# Hallucination Mitigation in Large Language Models
**At first, I wanna thanks for contributions of FDU question sets HalluQa**

## File Explanations:
## List of Evaluations files:
- HalluQA-main\calculate_metrics.py is for evaluating the *result of deepseek output answers*.
- HalluQA-main\calculate_metrics_mc.py is for evaluting the *multiple choice reponse* of deepseek output answer.
- deepseek(7b) responses(mc).json file is for *saving answer from deepseek*.
- questions to answer(QTA)(mc) is an *exchange module to put input questions in and saving the answer to .json file*.
- HalluQA(mc) is from FDU orignial question sets
- ### Links of HalluQA : [HalluQA](https://github.com/OpenMOSS/HalluQA)
 
...to be continued
